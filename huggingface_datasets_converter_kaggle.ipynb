{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nateraw/huggingface-datasets-converter/blob/main/huggingface_datasets_converter_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqv2odZcwKnD"
      },
      "source": [
        "# The Hugging Face Datasets Converter (Kaggle)\n",
        "\n",
        "This notebook allows you to convert a Kaggle dataset to a Hugging Face dataset. \n",
        "\n",
        "Follow the 4 simple steps below to take an existing dataset on Kaggle and convert it to a Hugging Face dataset, which can then be loaded with the `datasets` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGOpjXEZvx2q"
      },
      "source": [
        "# Step 1 - Setup\n",
        "\n",
        "Run the cell below to install required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF6KHSelR6n6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! git clone https://github.com/nateraw/huggingface-datasets-converter.git\n",
        "%cd /content/huggingface-datasets-converter\n",
        "! pip install -r requirements.txt\n",
        "! git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IWb91k6uoY7"
      },
      "source": [
        "# Step 2 - Authenticate with Kaggle\n",
        "\n",
        "Navigate to https://www.kaggle.com. Then go to the [Account tab of your user profile](https://www.kaggle.com/me/account) and select Create API Token. This will trigger the download of `kaggle.json`, a file containing your API credentials.\n",
        "\n",
        "Then run the cell below to upload kaggle.json to your Colab runtime.\n",
        "\n",
        "‚ö†Ô∏è It should be named exactly `kaggle.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3ZXT2hYr0GO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name in uploaded.keys():\n",
        "  print(f'User uploaded file \"{name}\" with length {len(uploaded[name])} bytes')\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find t.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Ly0RiFkCC6"
      },
      "source": [
        "Alternatively, you can upload the `kaggle.json` file manually to your working directory (probably the \"content\" folder) or using your Google Drive account ([see this](https://colab.research.google.com/notebooks/io.ipynb) for examples). Then run: \n",
        "\n",
        "```\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWHb2bVFvNQt"
      },
      "source": [
        "# Step 3 - Authenticate with Hugging Face ü§ó\n",
        "\n",
        "You'll need to authenticate with your Hugging Face account, so make sure to [sign up](https://huggingface.co/join) if you haven't already. \n",
        "\n",
        "Then, run the cell below and provide a token that has ***write access***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc4tD9APixHM"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9QKRsQNuJcI"
      },
      "source": [
        "# Step 4 - Convert From Kaggle\n",
        "\n",
        "Below, input the:\n",
        "\n",
        "- Kaggle ID of the dataset you'd like to upload (ex. `kaggleuser/dataset-name`)\n",
        "- Repo ID of the dataset repo you'd like to upload to (ex. `huggingface-user/dataset-name`).\n",
        "\n",
        "üí° You can find the Kaggle ID in the dataset URL.\n",
        "\n",
        "For example: if you want to convert [this dataset](https://www.kaggle.com/datasets/ruchi798/data-science-job-salaries), the ID is `ruchi798/data-science-job-salaries`.\n",
        "\n",
        "> üìù **Note** - The converter works best on csv and json datasets, so we suggest you use one of those :)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_datasets_converter.convert import notebook_converter_kaggle\n",
        "\n",
        "notebook_converter_kaggle()"
      ],
      "metadata": {
        "id": "himTovKElrZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Converted Datasets\n",
        "\n",
        "Now lets see how to load datasets we've converted!"
      ],
      "metadata": {
        "id": "2iNQmHp40QfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV\n",
        "\n",
        "For reference on loading CSV files using `datasets`, check [the docs](https://huggingface.co/docs/datasets/loading#csv).\n"
      ],
      "metadata": {
        "id": "GV0DCJSc2G9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example 1\n",
        "\n",
        "If your dataset contains just one CSV file and no additional json/zip/csv files, you can load it by providing the repo ID to `datasets.load_dataset`.\n",
        "\n",
        "- [Example Kaggle Dataset](https://www.kaggle.com/datasets/neuromusic/avocado-prices)\n",
        "- [Example Hugging Face Repo](https://huggingface.co/datasets/nateraw/avocado-prices)"
      ],
      "metadata": {
        "id": "KWE2kdMdE-2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset('nateraw/avocado-prices')\n",
        "ds"
      ],
      "metadata": {
        "id": "-kUAcAn42KPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get an example\n",
        "ds['train'][0]"
      ],
      "metadata": {
        "id": "8DHDdWZU2LM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example 2\n",
        "\n",
        "- [Example Kaggle Dataset](https://www.kaggle.com/datasets/unsdsn/world-happiness)\n",
        "- [Example Hugging Face Repo](https://huggingface.co/datasets/nateraw/world-happiness)\n",
        "\n",
        "This example has [multiple CSV files](https://huggingface.co/datasets/nateraw/world-happiness/tree/main) in it. In cases like these, we can refer directly to the file we need like this:"
      ],
      "metadata": {
        "id": "_maR5j5EFA9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset('nateraw/world-happiness', data_files='2019.csv')\n",
        "ds['train'][0]"
      ],
      "metadata": {
        "id": "-j83YgZaFKjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON\n",
        "\n",
        "- Example Kaggle Dataset\n",
        "- Example Hugging Face Repo\n",
        "\n",
        "With JSON, it's expected the files are in JSONL format. However, even JSONL formatted files sometimes can fail. So, here we'll show how to load directly with the built-in `json` Python package. \n",
        "\n",
        "For reference on loading JSON files using `datasets`, check [the docs](https://huggingface.co/docs/datasets/loading#json)."
      ],
      "metadata": {
        "id": "zAtS9lZPA9D0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example 1"
      ],
      "metadata": {
        "id": "Jna-YfJzEqst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Example Kaggle Dataset](https://www.kaggle.com/datasets/roamresearch/prescriptionbasedprediction)\n",
        "- [Example Hugging Face Repo](https://huggingface.co/datasets/nateraw/prescriptionbasedprediction)"
      ],
      "metadata": {
        "id": "cq5cYGRiEblS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pathlib import Path\n",
        "\n",
        "json_file = hf_hub_download('nateraw/prescriptionbasedprediction', 'roam_prescription_based_prediction.jsonl', repo_type='dataset')\n",
        "\n",
        "data = [json.loads(x) for x in Path(json_file).read_text().splitlines()]\n",
        "len(data)"
      ],
      "metadata": {
        "id": "6eJ3NPVqDVU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example 2\n",
        "\n",
        "- [Example Kaggle Dataset](https://kaggle.com/datasets/succinctlyai/midjourney-texttoimage)\n",
        "- [Example Hugging Face Repo](https://huggingface.co/datasets/nateraw/midjourney-texttoimage/)"
      ],
      "metadata": {
        "id": "O11jOUSL2xsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "json_file = hf_hub_download('nateraw/midjourney-texttoimage', 'general-01_2022_06_20.json', repo_type='dataset')\n",
        "data = json.loads(Path(json_file).read_text())\n",
        "\n",
        "print(f\"Keys: {data.keys()}\\n\\nNumber of messages: {len(data['messages'])}\")"
      ],
      "metadata": {
        "id": "BWiWmEXy3BXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}